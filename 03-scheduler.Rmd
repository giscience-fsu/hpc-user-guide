# Scheduler

[SLURM](https://slurm.schedmd.com/) is responsible for executing jobs across the cluster.
In contrast to running a "direct" R job from the command line on a server without a scheduler, this application takes care of the execution queue while accounting for other running processes.

In R, this is done via the R packages [rzmq](https://github.com/ropensci/rzmq) and [clustermq](https://github.com/mschubert/clustermq).
Both packages provide interfaces for the [zmq](http://zeromq.org/) library which in fact is doing the work of sending code requests of any language to SLURM.
While the _rzmq_ package is the technical interface to `zmq` in this combination, the _clustermq_ package is used by the user to start the pipeline of submitting a job to the scheduler.

Alternatives to the packages mentioned above are [batchtools](https://github.com/mllg/batchtools) and [future.batchtools](https://github.com/HenrikBengtsson/future.batchtools).

## First steps

Rather than calling a R script directly, you need to wrap your code into a function and invoke it using `clustermq::Q()`.
At first this might seem to be a more complex way to run R code than the interactive line-by-line approach at the command line.
But with time you will value the benefits of this approach:

- By being forced to "functionize" your code and putting in into smaller pieces, you'll diverge from long R scripts
- In combination with [drake](https://github.com/ropensci/drake) you are able to track already built targets and parallelize the building of intermediate targets

[drake](https://github.com/ropensci/drake) or its successor [targets](https://github.com/ropensci/targets) provides an interface to `clustermq` giving you the possibility of running multiple "targets" (which you can think of as one R script or one intermediate step) in parallel on the HPC.
These "targets" can again be parallelized.
For more information see the [drake manual](https://ropenscilabs.github.io/drake-manual/) and especially the section about [HPC computing](https://ropenscilabs.github.io/drake-manual/hpc.html).

Is is highly recommended that you set up an [SSH key](https://www.digitalocean.com/community/tutorials/how-to-configure-ssh-key-based-authentication-on-a-linux-server) (in case you have not done that already) for passwordless log in.

Even though {drake} is highly recommend, if you do not want to use it, you can also use `clustermq::Q()` directly.
And **no**, there is no other way to submit your jobs to the compute nodes of the cluster than by using any of the tools mentioned above.

See also the section [best practice](#best-practice) for more information on how to get started.

## SLURM commands

While the execution of jobs is explained in more detail in [Chapter 4](#submit-jobs), the following section aims familiarizing yourself with the usage of the scheduler.

The basic SLURM commands are

- `sinfo`: An overview of the current state of the nodes

```sh
sinfo

PARTITION    AVAIL  TIMELIMIT  NODES  STATE NODELIST
all*            up   infinite      4  alloc c[0-2],edi
all*            up   infinite      2   idle c[3-4]
frontend        up   infinite      1  alloc edi
threadripper    up   infinite      4  alloc c[0-2],edi
opteron         up   infinite      2   idle c[3-4]
```

- `squeue`: An overview of the current jobs that are queued, including information about running jobs

```sh
squeue

JOBID     PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
129_[2-5]    threadripper  cmq7381  patrick PD       0:00      1 (Resources)
121_2        threadripper  cmq7094  patrick  R    6:24:17      1 c1
121_3        threadripper  cmq7094  patrick  R    6:24:17      1 c2
129_1        threadripper  cmq7381  patrick  R    5:40:44      1 c0
```

- `sacct`: Overview of jobs that were submitted in the past including their end state

```sh
122             cmq7094     threadripper     (null)          0  COMPLETED      0:0
123             cmq7094     threadripper     (null)          0    PENDING      0:0
121             cmq7094     threadripper     (null)          0    PENDING      0:0
125             cmq6623     threadripper     (null)          0     FAILED      1:0
126             cmq6623     threadripper     (null)          0     FAILED      1:0
127             cmq6623     threadripper     (null)          0     FAILED      1:0
128             cmq6623     threadripper     (null)          0     FAILED      1:0
124             cmq6623     threadripper     (null)          0     FAILED      1:0
130             cmq7381     threadripper     (null)          0    PENDING      0:0
```

- `scancel`: Cancel running jobs using the job ID identifier
