# Submitting jobs

## `clustermq` setup

Every job submission is done via `clustermq::Q()` (either directly or via `drake`). 
See the setup instructions in the [clustermq](https://github.com/mschubert/clustermq/wiki) package on how to setup the package.

First, you need to set some options in your `.Rprofile` (on the master node):

```
options(
    clustermq.scheduler = "slurm",
    clustermq.template = "/path/to/file/below"
)
```

Note that you can have multiple `.Rprofile` files: One at the your home directory which is being used by your default R interpreter and one per project, at the root of your project directory.
This enables you to use custom R versions for each project

Once you did this, you should be able to run the [example](https://github.com/mschubert/clustermq) in the README of the _clustermq_ package.
It is a very simple example which finishes in a few seconds.
If it does not work, you either did something wrong or the nodes are busy.
Check with `sinfo` and `squeue`.
Otherwise see the [Troubleshooting](#troubleshooting) chapter.

```{block, type='rmdcaution'}
Be aware of setting `n_cpus` in the `template` argument of `clustermq::Q()` if your submitted job is parallelized!
If you submit a job that is parallelized without telling the scheduler, the scheduler will reserve 1 core for this job (because it thinks it is sequential) but in fact multiple processes will spawn. 
This will potentially affect all running processes on the server since the scheduler will accept more processing than it actually can take.
```

## From the master node

If you start jobs from the master node, you need to set the `.Rprofile` options given above.
Note that you can add any bash commands into the scripts between the `SBATCH` section and the final R call.
For example, one of my templates looks like this:

```sh
#!/bin/sh
#SBATCH --job-name={{ job_name }}
#SBATCH --partition=normal
#SBATCH --output={{ log_file | /dev/null }} # you can add .%a for array index
#SBATCH --error={{ log_file | /dev/null }}
#SBATCH --cpus-per-task={{ n_cpus }}
#SBATCH --array=1-{{ n_jobs }}

cd path/to/project

spack load r@<version>

# add more spack libraries here

CMQ_AUTH={{ auth }} R --no-save --no-restore -e 'clustermq:::worker("{{ master }}")'
```

Note: The `#` signs are no mistakes here, they are no "comment" signs in this context. 
The `SBATCH` commands will be executed here.

You can simply copy it and adjust it to your needs (set the right path to your project and specify the R version you want to use).

## Allocating resources

When submitting jobs via `clustermq::Q()`, it is important to tell the scheduler how many cores should be reserved via the `n_jobs` argument.
If omitted, the scheduler will plan with one core (= sequential execution) although your submitted code will eventually spawn multiple workers along the process.

There are two ways to specify this setting, depending on which approach you use:

1. via `clustermq::Q()` directly

Here you can directly set the `n_cpus` argument to the desired value. 
It will then be passed to the `slurm_clustermq.tmpl` file which has a line containing `#SBATCH --cpus-per-task{{ n_cpus }}`.
This tells the scheduler how many resources (here cpus) your job needs.
Note that the maximum number is `n_cpus = 32` as processes cannot be split across nodes.

2. via `drake::make()` (recommended)

In `drake::make()` you can set this option via the argument `template = list(n_cpus = X)`.
See section ["The resources column for transient workers"](https://ropenscilabs.github.io/drake-manual/hpc.html#advanced-options) in the drake manual.

```{block, type='rmdcaution'}
Please think upfront how many cpus your task requires. 
If you use something like `mclapply(cores = 20)` but set `n_cpus` in the Slurm template to 16, you will just get 16 cpus.
The remaining 4 workers are spawned but will always be in "waiting mode" as you only requested 16 cores.
```

Furthermore, if you want to use all ressources of a node and run into memory problems, try reducing the number of cpus.
Each node has 126 GB RAM available which gets split up to the nodes. 
If you scale down the number of cpus, you will have more memory/cpu available.

## Monitoring progress

When submitting jobs you can track its progress by specifying a `log_file` in the `clustermq::Q()` call, e.g. `clustermq::Q(template = list(log_file = path/to/file))`.

For `drake`, the equivalent is to specify `console_log_file()` in either `make()` or `drake_config()`.

If your jobs are running on a node, you can SSH into the node, e.g. `ssh c0`.
In the node you can take a look at the current load by using `htop`.
Note that you can only login if you have a running progress in a specific node.

Another option is to take a look [Ganglia](http://141.35.158.107/ganglia/?r=hour&cs=&ce=&m=load_one&s=by+name&c=OpenHPC&tab=m&vn=&hide-hf=false) to see the load of the HPC.

## Summary

1. Decide which approach you want to use

- `drake::make(parallelism = "clustermq", n_jobs = 1, template = list(n_cpus = X, log_file = Y))` (recommended!)
- `clustermq::Q(template = list(n_cpus = X, log_file = Y))`

2. You need to have a Slurm template file in your project directory. This template needs to be linked in your `.Rprofile` with `options(clustermq.template = "/path/to/file")`. The following settings are required:

- `R version`
- `--cpus-per-task`
- `--log_file`
- A `cd` command pointing to your project directory

## Best practice {#best-practice}

If you submit a job, you submit it to ONE node.
You can submit as many tasks as you want in separate R sessios, they will be processed as ranked in the queue of the scheduler.
However, submitting single jobs that finish quickly is tedious.
The same applies to the submission of multiple jobs in separate R sessions.

These two points are the reason why it is *highly* recommended to use `drake`.
By using `drake`, all of your intermediate R objects are "targets". 
You can specify any number of targets that should be build when calling `drake::make()`.
`drake` will take care that for each target as separate job is created which is then added to the Slurm queue.

For example, if you want to build three R objects named `object1`, `object2` and `object3` in parallel, one on each node:

`drake::make(plan, targets = c("object1", "object2", "object3"), jobs = 3, template = list(n_cpus = 16, log_file = "/path/to/log.txt"))`

- Creates three jobs which are added to the Slurm queue
- Each jobs requires 16 cores
- The job is finished once all targets have been built.

After they are finished, they will be marked as "built" and added to a cache directory by `drake`, so you cannot accidentally rebuild them (unless you change somehting substantial in the code).

If you follow this practive, the only thing you need to execute on the cluster will be this call (after you initialized the config by sourcing your `drake.R` file).


