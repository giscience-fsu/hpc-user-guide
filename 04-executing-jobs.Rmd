# Submitting jobs

## Requirements

In order to run anything on the server (including the example above) it is required to install R and other system libraries that are need for your R packages.
Please see the chapter about [Spack](#spack) for more information if you haven't done so yet.

## `clustermq` setup

Every job submission is done via `clustermq::Q()`. 
See the setup instructions in the [clustermq](https://github.com/mschubert/clustermq/wiki) package on how to setup the package.

You need to set some options in your `.Rprofile`:

```
options(
    clustermq.scheduler = "slurm",
    clustermq.template = "/path/to/file/below"
)
```

Note that you can have multiple `.Rprofile` files: One at the your home directory which is being used by your default R interpreter and one per project, at the root of your project directory.
This enables you to load custom modules via `spack` for each project.

Once you did this, you should be able to run the [example](https://github.com/mschubert/clustermq) in the README of the _clustermq_ package.
It is a very simple example which finishes in a few seconds.
If it does not work, you either did something wrong or the nodes are busy.
Check with `sinfo` and `squeue`.
Otherwise see the [Troubleshooting](#troubleshooting) chapter.

**Be aware of setting `n_jobs` in the `template` argument of `clustermq::Q()` if your submitted job is parallelized!
If you submit a job that is parallelized without telling the scheduler, the scheduler will reserve 1 core for this job (because it thinks it is sequential) but in fact multiple processes will spawn. 
This will potentially affect all running processes on the server since the scheduler will accept more processing than it actually can take.**
See [here] for more information.

## From the SMS

If you start jobs right from the SMS, you need to set the options given above.
Note that you can add any bash commands into the scripts between the `SBATCH` section and the final R call.
For example, one of my templates looks like this:

```sh
#!/bin/sh
#SBATCH --job-name={{ job_name }}
#SBATCH --partition=normal
#SBATCH --output={{ log_file | /dev/null }} # you can add .%a for array index
#SBATCH --error={{ log_file | /dev/null }}
#SBATCH --array=1-{{ n_jobs }}

cd path/to/project

# load spack modules
spack env activate <project>
spack load r@3.5.1
spack load gdal
spack load proj
spack load geos
spack load udunits2

R --no-save --no-restore -e 'clustermq:::worker("{{ master }}")'
```

Note: The `#` signs are no mistake here, they are no "comment" signs in this context. 
The `SBATCH` commands will be executed here.

## From your local machine (via SSH) {#ssh-mode}

You can use the servers right from your local machine without executing the job from the server explicitly.
This works by sending requests to the scheduler via SSH.
Once the jobs are finished, the resulting objects are available on your local machine.
See the [ssh connector](https://github.com/mschubert/clustermq/wiki/Configuration#ssh-connector) section in the `clustermq` wiki for more detailed instructions.

To use this approach, you need to set the following `options()` in your projects `.Rprofile` on your **local** machine:

```r
options(
    clustermq.scheduler = "ssh",
    clustermq.ssh.host = "user@host", # use your user and host, obviously
    clustermq.ssh.log = "~/cmq_ssh.log" # log for easier debugging
)
```

Now every call to `clustermq::Q()` does the following:

1. An SSH connection to the server is established 
1. Your `~/.bashrc` file on the SMS is sourced and the R function call to `clustermq:::ssh_proxy()` is being executed.
1. This R call again uses the `options()` from your default `.Rprofile` which has a pointer to a `slurm_clustermq.tmpl` file which is then being called.

```r
clustermq:::ssh_proxy(ctl=54306, job=50570)
master ctl listening at: tcp://localhost:54306
forwarding local network from: tcp://gisc:8800
sent PROXY_UP to master ctl
received common data:
sent PROXY_READY to master ctl
received: PROXY_CMDqsys$submit_jobs(log_file = "/home/patrick/log.txt", n_jobs = 3)
```

3. The final job request is send to the scheduler which then runs the job / adds it to the queue (last line of the block above).

While this is very convenient as it enables processing on the server without even logging in, it currently has one downside:
The first call to `clustermq:::ssh_proxy()` takes the R configuration (= `.Rprofile`) specified in your default R interpreter on the SMS.
Here, you can specify the location of your `slurm_clustermq.tmpl` file which again loads your desired libraries via `spack` and changes the directory to your project directory so that your _packrat_ libraries are used (for example).
However, this means that you cannot work with multiple projects at the same with using the SSH approach as you can only point to one Slurm template file at the same time.

In summary the pipeline of the call is: `clustermq::Q()` (local) -> R (remote) -> `slurm_clustermq.tmpl` (specified in `.Rprofile`) (remote) -> SLURM -> processing

### Requirements 

#### Local

- The `clustermq` package needs to be installed
- `clustermq.scheduler` needs to be set to `"ssh"` in `options()`
- `clustermq.ssh.host` needs to be specified `options()`

#### Remote

On the server, you need to specify the location of the `slurm_clustermq.tmpl` file in `options()` in the `.Rprofile` of your default R interpreter:

```r
options(
  clustermq.scheduler = "slurm", 
  clustermq.template = "<path/to/file>"
)
```

Furthermore, all required R packages need to be installed on the server.

## Allocating resources

When submitting jobs via `clustermq::Q()`, it is important to tell the scheduler how many cores should be reserved via the `n_jobs` argument.
If omitted, the scheduler will plan with 1 core (= sequential execution) although your submitted code will eventually spawn multiple workers along the process.

There are two ways to specify this setting, depending on which approach you use:

1. via `clustermq::Q()` directly

Here you can directly set the `n_jobs` argument to the desired value. 
It will then passed to the `slurm_clustermq.tmpl` file which has a line containing `#SBATCH --array=1-{{ n_jobs }}`.
This tells the scheduler how many resources (here cpus) your job needs.

2. via `drake::make()` (recommended)

In `drake::make()` you can set two arguments: `jobs` and `template(list(n_jobs = <value>))`. The first one determines how many jobs should be added to the Slurm queue. The second one tells Slurm how many resources each job needs.
You can further narrow down the requirements for a target by specifying these already in the plan. 
See section ["The resources column for transient workers"](https://ropenscilabs.github.io/drake-manual/hpc.html#advanced-options) in the drake manual.

## Monitoring progress

When submitting jobs you can track its progress by specifying a `log_file` in the `clustermq::Q()` call, e.g. `clustermq::Q(template = list(log_file = path/to/file))`.

If your jobs are running on a node, you can SSH into it, e.g. `ssh c0`.
In the node you can take a look at the current load by using `htop`.
Note that you can only login if you have a running progress in a specific node.
